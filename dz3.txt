1) Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?

micro: метрики вычисляются глобально, т.е. для каждого класса суммируются полные истинные положительные значения, ложные негативные и ложные позитивные срабатывания.

macro: для каждого класса метрики находятся раздельно, после чего берется их невзвешенное значение. Этот вариант не учитывает дисбаланс метрик.

weighted: показатели для каждого класса рассчитываются отдельно, затем  находится среднее взвешенное значение. Этот вариант позволяет учитывать дисбаланс метрик. 

2) В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

Алгоритмлгоритм разбиения деревьев:
		Xgboost - для выбора разбиения использует сортировку и модели, основанные на анализе гистограмм.
		LightGBM - Для выбора критерия разбиения используется техника односторонней выборки на основе градиента Gradient-based One-Side Sampling (GOSS).
		CatBoost - не нашла информации
	
Обработка категориальных переменных по каждому алгоритму:
	CatBoost - умеет работать со строковыми и числовыми категорийными переменными 
	LightGBM - умеет работать с числовыми категорийными переменными, со строковыми нет
	XGBoost - не умеет обрабатывать категорийные переменные

Скорость работы алгоритма:
	CatBoost - самый медленный
	LightGBM - самый быстрый
	XGBoost - средний по производительности 


